{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4561339643247178,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018201674554058973,
      "grad_norm": 1.1744756698608398,
      "learning_rate": 7.35e-05,
      "loss": 5.0199,
      "step": 50
    },
    {
      "epoch": 0.03640334910811795,
      "grad_norm": 1.392709493637085,
      "learning_rate": 0.00014849999999999998,
      "loss": 4.4548,
      "step": 100
    },
    {
      "epoch": 0.05460502366217692,
      "grad_norm": 1.5490071773529053,
      "learning_rate": 0.00022349999999999998,
      "loss": 4.3665,
      "step": 150
    },
    {
      "epoch": 0.0728066982162359,
      "grad_norm": 1.1224703788757324,
      "learning_rate": 0.0002985,
      "loss": 4.3812,
      "step": 200
    },
    {
      "epoch": 0.09100837277029487,
      "grad_norm": 3.703777551651001,
      "learning_rate": 0.00029693749999999995,
      "loss": 4.3818,
      "step": 250
    },
    {
      "epoch": 0.10921004732435384,
      "grad_norm": 1.610640287399292,
      "learning_rate": 0.00029381249999999997,
      "loss": 4.5033,
      "step": 300
    },
    {
      "epoch": 0.12741172187841282,
      "grad_norm": 1.4608128070831299,
      "learning_rate": 0.0002906875,
      "loss": 4.3727,
      "step": 350
    },
    {
      "epoch": 0.1456133964324718,
      "grad_norm": 1.474850058555603,
      "learning_rate": 0.00028756249999999995,
      "loss": 4.4157,
      "step": 400
    },
    {
      "epoch": 0.16381507098653075,
      "grad_norm": 1.1559956073760986,
      "learning_rate": 0.00028443749999999997,
      "loss": 4.299,
      "step": 450
    },
    {
      "epoch": 0.18201674554058975,
      "grad_norm": 1.098732829093933,
      "learning_rate": 0.0002813125,
      "loss": 4.3234,
      "step": 500
    },
    {
      "epoch": 0.2002184200946487,
      "grad_norm": 1.2666594982147217,
      "learning_rate": 0.00027818749999999995,
      "loss": 4.3194,
      "step": 550
    },
    {
      "epoch": 0.21842009464870768,
      "grad_norm": 0.8028132915496826,
      "learning_rate": 0.00027506249999999997,
      "loss": 4.3181,
      "step": 600
    },
    {
      "epoch": 0.23662176920276665,
      "grad_norm": 0.9274430274963379,
      "learning_rate": 0.0002719375,
      "loss": 4.2957,
      "step": 650
    },
    {
      "epoch": 0.25482344375682564,
      "grad_norm": 1.1855610609054565,
      "learning_rate": 0.00026881249999999995,
      "loss": 4.341,
      "step": 700
    },
    {
      "epoch": 0.2730251183108846,
      "grad_norm": 0.9960570335388184,
      "learning_rate": 0.0002656875,
      "loss": 4.2452,
      "step": 750
    },
    {
      "epoch": 0.2912267928649436,
      "grad_norm": 1.2308454513549805,
      "learning_rate": 0.0002625625,
      "loss": 4.3341,
      "step": 800
    },
    {
      "epoch": 0.30942846741900254,
      "grad_norm": 1.162805438041687,
      "learning_rate": 0.00025943749999999996,
      "loss": 4.2942,
      "step": 850
    },
    {
      "epoch": 0.3276301419730615,
      "grad_norm": 0.7838090658187866,
      "learning_rate": 0.0002563125,
      "loss": 4.3797,
      "step": 900
    },
    {
      "epoch": 0.3458318165271205,
      "grad_norm": 1.5511324405670166,
      "learning_rate": 0.0002531875,
      "loss": 4.3042,
      "step": 950
    },
    {
      "epoch": 0.3640334910811795,
      "grad_norm": 1.4262661933898926,
      "learning_rate": 0.00025006249999999996,
      "loss": 4.3294,
      "step": 1000
    },
    {
      "epoch": 0.38223516563523846,
      "grad_norm": 0.9376838207244873,
      "learning_rate": 0.0002469375,
      "loss": 4.2376,
      "step": 1050
    },
    {
      "epoch": 0.4004368401892974,
      "grad_norm": 1.1387507915496826,
      "learning_rate": 0.0002438125,
      "loss": 4.5146,
      "step": 1100
    },
    {
      "epoch": 0.4186385147433564,
      "grad_norm": 1.448699712753296,
      "learning_rate": 0.00024068749999999996,
      "loss": 4.2525,
      "step": 1150
    },
    {
      "epoch": 0.43684018929741536,
      "grad_norm": 1.6814039945602417,
      "learning_rate": 0.00023756249999999998,
      "loss": 4.3386,
      "step": 1200
    },
    {
      "epoch": 0.4550418638514743,
      "grad_norm": 0.5917776226997375,
      "learning_rate": 0.0002344375,
      "loss": 4.209,
      "step": 1250
    },
    {
      "epoch": 0.4732435384055333,
      "grad_norm": 1.499951720237732,
      "learning_rate": 0.00023131249999999996,
      "loss": 4.2654,
      "step": 1300
    },
    {
      "epoch": 0.49144521295959226,
      "grad_norm": 5.214912414550781,
      "learning_rate": 0.00022818749999999998,
      "loss": 4.2772,
      "step": 1350
    },
    {
      "epoch": 0.5096468875136513,
      "grad_norm": 0.9621526598930359,
      "learning_rate": 0.0002250625,
      "loss": 4.4294,
      "step": 1400
    },
    {
      "epoch": 0.5278485620677102,
      "grad_norm": 1.4588507413864136,
      "learning_rate": 0.00022193749999999997,
      "loss": 4.4098,
      "step": 1450
    },
    {
      "epoch": 0.5460502366217692,
      "grad_norm": 1.1103326082229614,
      "learning_rate": 0.00021881249999999999,
      "loss": 4.1388,
      "step": 1500
    },
    {
      "epoch": 0.5642519111758282,
      "grad_norm": 1.095812201499939,
      "learning_rate": 0.00021568749999999998,
      "loss": 4.3035,
      "step": 1550
    },
    {
      "epoch": 0.5824535857298871,
      "grad_norm": 1.239342451095581,
      "learning_rate": 0.00021256249999999997,
      "loss": 4.2544,
      "step": 1600
    },
    {
      "epoch": 0.6006552602839461,
      "grad_norm": 1.4167524576187134,
      "learning_rate": 0.0002094375,
      "loss": 4.341,
      "step": 1650
    },
    {
      "epoch": 0.6188569348380051,
      "grad_norm": 1.2258282899856567,
      "learning_rate": 0.00020631249999999998,
      "loss": 4.2798,
      "step": 1700
    },
    {
      "epoch": 0.637058609392064,
      "grad_norm": 1.2624738216400146,
      "learning_rate": 0.00020318749999999997,
      "loss": 4.3077,
      "step": 1750
    },
    {
      "epoch": 0.655260283946123,
      "grad_norm": 1.3001956939697266,
      "learning_rate": 0.0002000625,
      "loss": 4.3173,
      "step": 1800
    },
    {
      "epoch": 0.673461958500182,
      "grad_norm": 1.024364948272705,
      "learning_rate": 0.00019693749999999998,
      "loss": 4.1729,
      "step": 1850
    },
    {
      "epoch": 0.691663633054241,
      "grad_norm": 0.967024028301239,
      "learning_rate": 0.00019381249999999997,
      "loss": 4.2701,
      "step": 1900
    },
    {
      "epoch": 0.7098653076082999,
      "grad_norm": 1.8230690956115723,
      "learning_rate": 0.0001906875,
      "loss": 4.4153,
      "step": 1950
    },
    {
      "epoch": 0.728066982162359,
      "grad_norm": 0.8995876312255859,
      "learning_rate": 0.00018756249999999999,
      "loss": 4.1387,
      "step": 2000
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 1.2334587574005127,
      "learning_rate": 0.00018443749999999998,
      "loss": 4.454,
      "step": 2050
    },
    {
      "epoch": 0.7644703312704769,
      "grad_norm": 1.8723160028457642,
      "learning_rate": 0.0001813125,
      "loss": 4.2082,
      "step": 2100
    },
    {
      "epoch": 0.7826720058245359,
      "grad_norm": 2.3980705738067627,
      "learning_rate": 0.0001781875,
      "loss": 4.2404,
      "step": 2150
    },
    {
      "epoch": 0.8008736803785949,
      "grad_norm": 0.9763818383216858,
      "learning_rate": 0.00017506249999999998,
      "loss": 4.3136,
      "step": 2200
    },
    {
      "epoch": 0.8190753549326538,
      "grad_norm": 1.3428187370300293,
      "learning_rate": 0.00017193749999999997,
      "loss": 4.1667,
      "step": 2250
    },
    {
      "epoch": 0.8372770294867128,
      "grad_norm": 1.1943609714508057,
      "learning_rate": 0.0001688125,
      "loss": 4.2898,
      "step": 2300
    },
    {
      "epoch": 0.8554787040407718,
      "grad_norm": 1.3288521766662598,
      "learning_rate": 0.00016568749999999998,
      "loss": 4.2243,
      "step": 2350
    },
    {
      "epoch": 0.8736803785948307,
      "grad_norm": 1.3155326843261719,
      "learning_rate": 0.00016256249999999997,
      "loss": 4.1194,
      "step": 2400
    },
    {
      "epoch": 0.8918820531488897,
      "grad_norm": 1.6326110363006592,
      "learning_rate": 0.0001594375,
      "loss": 4.0498,
      "step": 2450
    },
    {
      "epoch": 0.9100837277029487,
      "grad_norm": 1.1253864765167236,
      "learning_rate": 0.00015631249999999998,
      "loss": 4.1682,
      "step": 2500
    },
    {
      "epoch": 0.9282854022570076,
      "grad_norm": 0.5367635488510132,
      "learning_rate": 0.00015318749999999998,
      "loss": 4.2357,
      "step": 2550
    },
    {
      "epoch": 0.9464870768110666,
      "grad_norm": 0.9125955104827881,
      "learning_rate": 0.0001500625,
      "loss": 4.2045,
      "step": 2600
    },
    {
      "epoch": 0.9646887513651256,
      "grad_norm": 1.383235216140747,
      "learning_rate": 0.0001469375,
      "loss": 4.2945,
      "step": 2650
    },
    {
      "epoch": 0.9828904259191845,
      "grad_norm": 1.1595239639282227,
      "learning_rate": 0.00014381249999999998,
      "loss": 4.2845,
      "step": 2700
    },
    {
      "epoch": 1.0010921004732436,
      "grad_norm": 1.0152921676635742,
      "learning_rate": 0.00014068749999999997,
      "loss": 4.3424,
      "step": 2750
    },
    {
      "epoch": 1.0192937750273026,
      "grad_norm": 1.18007493019104,
      "learning_rate": 0.0001375625,
      "loss": 4.183,
      "step": 2800
    },
    {
      "epoch": 1.0374954495813615,
      "grad_norm": 0.5964809656143188,
      "learning_rate": 0.00013443749999999998,
      "loss": 4.2317,
      "step": 2850
    },
    {
      "epoch": 1.0556971241354205,
      "grad_norm": 1.1708811521530151,
      "learning_rate": 0.00013131249999999997,
      "loss": 4.2095,
      "step": 2900
    },
    {
      "epoch": 1.0738987986894795,
      "grad_norm": 0.9690108895301819,
      "learning_rate": 0.0001281875,
      "loss": 4.2294,
      "step": 2950
    },
    {
      "epoch": 1.0921004732435384,
      "grad_norm": 1.0593136548995972,
      "learning_rate": 0.00012506249999999998,
      "loss": 4.0984,
      "step": 3000
    },
    {
      "epoch": 1.1103021477975974,
      "grad_norm": 1.401853084564209,
      "learning_rate": 0.00012193749999999999,
      "loss": 4.1263,
      "step": 3050
    },
    {
      "epoch": 1.1285038223516564,
      "grad_norm": 1.4772627353668213,
      "learning_rate": 0.0001188125,
      "loss": 4.1998,
      "step": 3100
    },
    {
      "epoch": 1.1467054969057153,
      "grad_norm": 1.218949317932129,
      "learning_rate": 0.00011568749999999999,
      "loss": 4.3044,
      "step": 3150
    },
    {
      "epoch": 1.1649071714597743,
      "grad_norm": 1.4564894437789917,
      "learning_rate": 0.00011256249999999998,
      "loss": 3.9825,
      "step": 3200
    },
    {
      "epoch": 1.1831088460138333,
      "grad_norm": 1.3532989025115967,
      "learning_rate": 0.0001094375,
      "loss": 4.2267,
      "step": 3250
    },
    {
      "epoch": 1.2013105205678922,
      "grad_norm": 1.1913328170776367,
      "learning_rate": 0.00010631249999999999,
      "loss": 4.1563,
      "step": 3300
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 0.7044296860694885,
      "learning_rate": 0.00010318749999999998,
      "loss": 4.2228,
      "step": 3350
    },
    {
      "epoch": 1.2377138696760102,
      "grad_norm": 0.7927632927894592,
      "learning_rate": 0.0001000625,
      "loss": 4.2288,
      "step": 3400
    },
    {
      "epoch": 1.2559155442300691,
      "grad_norm": 0.9038486480712891,
      "learning_rate": 9.693749999999999e-05,
      "loss": 4.2113,
      "step": 3450
    },
    {
      "epoch": 1.274117218784128,
      "grad_norm": 1.110560417175293,
      "learning_rate": 9.381249999999998e-05,
      "loss": 4.0718,
      "step": 3500
    },
    {
      "epoch": 1.292318893338187,
      "grad_norm": 2.0827455520629883,
      "learning_rate": 9.06875e-05,
      "loss": 4.3561,
      "step": 3550
    },
    {
      "epoch": 1.310520567892246,
      "grad_norm": 1.7745376825332642,
      "learning_rate": 8.75625e-05,
      "loss": 4.2718,
      "step": 3600
    },
    {
      "epoch": 1.328722242446305,
      "grad_norm": 1.3473098278045654,
      "learning_rate": 8.443749999999999e-05,
      "loss": 4.0433,
      "step": 3650
    },
    {
      "epoch": 1.346923917000364,
      "grad_norm": 0.9775756597518921,
      "learning_rate": 8.131249999999999e-05,
      "loss": 4.1208,
      "step": 3700
    },
    {
      "epoch": 1.3651255915544231,
      "grad_norm": 1.3100206851959229,
      "learning_rate": 7.81875e-05,
      "loss": 4.1036,
      "step": 3750
    },
    {
      "epoch": 1.383327266108482,
      "grad_norm": 1.7426953315734863,
      "learning_rate": 7.506249999999999e-05,
      "loss": 4.0545,
      "step": 3800
    },
    {
      "epoch": 1.401528940662541,
      "grad_norm": 1.1776659488677979,
      "learning_rate": 7.19375e-05,
      "loss": 3.9294,
      "step": 3850
    },
    {
      "epoch": 1.4197306152165998,
      "grad_norm": 1.5955579280853271,
      "learning_rate": 6.88125e-05,
      "loss": 4.1066,
      "step": 3900
    },
    {
      "epoch": 1.437932289770659,
      "grad_norm": 0.9531325101852417,
      "learning_rate": 6.568749999999999e-05,
      "loss": 4.1981,
      "step": 3950
    },
    {
      "epoch": 1.4561339643247178,
      "grad_norm": 0.9511522650718689,
      "learning_rate": 6.25625e-05,
      "loss": 4.2482,
      "step": 4000
    }
  ],
  "logging_steps": 50,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.14675192071168e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
